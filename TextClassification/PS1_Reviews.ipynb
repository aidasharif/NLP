{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of PS1-Reviews.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NULabTMN/hw1-aidasharif1365/blob/master/PS1_Reviews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jc2R3x6QSIFi"
      },
      "source": [
        "In this experiment, you will explore the accuracy of sentiment classificaiton using different feature representations of text documents.\n",
        "\n",
        "First, you will implement `createBasicFeatures`, which creates a sparse matrix representation of a collection of documents. For this exercise, you should have a feature for each word containing at least one alphabetic character. You may use the `numpy` and `sklearn` packages to help with implementing a sparse matrix.\n",
        "\n",
        "Then, you will implement `createFancyFeatures`, which can specify at any other features you choose to help improve performance on the classification task.\n",
        "\n",
        "The two code blocks at the end train and evaluate two models—logistic regression with L1 and L2 regularization—using your featurization functions. Besides held-out classification accuracy with 10-fold cross-validation, you will also see the features in each class given high weights by the model.\n",
        "\n",
        "A helpful resource for getting up to speed with vector representations of documents is the first two chapters of Delip Rao and Brian McMahan, _Natural Language Processing with PyTorch_, O'Reilly, 2019.  You should be able to <a href=\"https://learning.oreilly.com/library/view/natural-language-processing/9781491978221/\">read it online</a> via the Northeastern Library's subscription using a <tt>northeastern.edu</tt> email address."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdVS67_HNRmW"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "import json\n",
        "import spacy\n",
        "import string\n",
        "import requests\n",
        "import collections\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_validate,LeaveOneOut,KFold\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer,TfidfTransformer\n",
        "from spacy.lang.en import English\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzjMY8fYQbB6",
        "cellView": "both"
      },
      "source": [
        "# read in the movie review corpus\n",
        "def readReviews():\n",
        "  raw = requests.get(\"https://raw.githubusercontent.com/mutherr/CS6120-PS1-data/master/cornell_reviews.json\").text.strip()\n",
        "  corpus = [json.loads(line) for line in raw.split(\"\\n\")]\n",
        "\n",
        "  return corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqpFyxguXLMR"
      },
      "source": [
        "#stems the tokens using porterstemmer\n",
        "def stemSentence(sentence):\n",
        "  porter = PorterStemmer()\n",
        "  token_words=word_tokenize(sentence)\n",
        "  stem_sentence=[]\n",
        "  for word in token_words:\n",
        "      stem_sentence.append(porter.stem(word))\n",
        "      stem_sentence.append(\" \")\n",
        "  return \"\".join(stem_sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqJG6EXSw-gH"
      },
      "source": [
        "#lemmatize tokens using WordNetLemmatizer\n",
        "def lemmaSentence(sentence):\n",
        "  wordnet_lemmatizer = WordNetLemmatizer()\n",
        "  token_words=word_tokenize(sentence)\n",
        "  lemma_sentence=[]\n",
        "  for word in token_words:\n",
        "      lemma_sentence.append(wordnet_lemmatizer.lemmatize(word))\n",
        "      lemma_sentence.append(\" \")\n",
        "  return \"\".join(lemma_sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYayOe2hnt6P"
      },
      "source": [
        "#this function removes stopwords(the dict is passed to it as an input) and punctuations\n",
        "def remove_stopwords(sentence,stopwords_dict):\n",
        "  punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "  no_punct = \"\"\n",
        "  token_words=word_tokenize(sentence)\n",
        "  no_stop=' '.join([word for word in token_words if word not in stopwords_dict])\n",
        "\n",
        "  for char in no_stop:\n",
        "    if char not in punctuations:\n",
        "        no_punct = no_punct + char\n",
        "  return no_punct"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qvd3I95FT01D"
      },
      "source": [
        "This is where you will implement two functions to featurize the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15hcWFxW0t35"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "039fPQcF7OkN"
      },
      "source": [
        "# NB: The current contents are for testing only\n",
        "# This function should return: \n",
        "#  -a sparse numpy matrix of document features\n",
        "#  -a list of the correct class for each document\n",
        "#  -a list of the vocabulary used by the features, such that the ith term of the\n",
        "#    list is the word whose counts appear in the ith column of the matrix. \n",
        "\n",
        "# This function should create a feature representation using all tokens that\n",
        "# contain an alphabetic character.\n",
        "def createBasicFeatures(corpus):\n",
        "\n",
        "  texts=[]\n",
        "  vocab=[]\n",
        "  classes=[]\n",
        "\n",
        "  for i in range(len(corpus)):\n",
        "    texts.append(corpus[i][\"text\"])\n",
        "    classes.append(corpus[i][\"class\"])\n",
        "\n",
        "  #using countvectorizer to count words in documents\n",
        "  one_hot_vectorizer = CountVectorizer()\n",
        "  one_hot_matrix = one_hot_vectorizer.fit_transform(texts)\n",
        "  vocab_dict = (one_hot_vectorizer.vocabulary_)\n",
        "\n",
        "  for k in vocab_dict:\n",
        "    vocab.append(k)\n",
        "\n",
        "  return one_hot_matrix,classes,vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SB5bK22m2Em",
        "outputId": "38c61ec8-4795-4dc1-c49b-5d0ad568fd04"
      },
      "source": [
        "corpus = readReviews()\n",
        "X,y,vocab = createBasicFeatures(corpus)\n",
        "runEvaluation(X, y, vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------L1 Norm-----------\n",
            "The model's average accuracy is 0.828500\n",
            "The most informative terms for pos are: ['copious', 'inauspiciously', 'ascension', 'arija', 'oise', 'tilly', 'pansy', 'homeland', 'exhibit', 'kaleidoscopic', 'feminist', 'escher', 'unsigned', 'bogie', 'yagher', 'tannek', 'eligible', 'swedish', 'sympathy', 'charades']\n",
            "The most informative terms for neg are: ['ankles', 'boasting', 'torpor', 'moff', 'criticisms', 'amazin', 'khe', 'saying', 'gheorghe', 'reprocessed', 'races', 'yzma', 'mineo', 'garde', 'midknight', 'techie', 'cilvilization', 'beers', 'facts', 'spectaculars']\n",
            "----------L2 Norm-----------\n",
            "The model's average accuracy is 0.833000\n",
            "The most informative terms for pos are: ['unsigned', 'stacey', 'aged', 'tannek', 'bargaining', 'porting', 'tilly', 'pansy', 'inauspiciously', 'escher', 'necks', 'isolationist', 'moody', 'ascension', '_____', 'shy', 'unabated', 'cant', 'mcconaughey', 'oise']\n",
            "The most informative terms for neg are: ['techie', 'khe', 'moff', 'ankles', 'organisations', '_kingpin_', 'saying', 'races', 'bigtime', 'initials', 'cilvilization', 'fortenberry', 'spectaculars', 'boasting', 'coppolas', 'torpor', 'lolipop', 'wire', 'fireflies', 'island']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qj0YQcAw7zrH"
      },
      "source": [
        "stopwords_dict = Counter(stop_words)\n",
        "pos_dict=collections.defaultdict(lambda:0)\n",
        "neg_dict=collections.defaultdict(lambda:0)\n",
        "punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "for i in range(len(corpus)):\n",
        "  sentence=(corpus[i][\"text\"])\n",
        "  token_words=word_tokenize(sentence)\n",
        "  if corpus[i][\"class\"]=='pos':\n",
        "    for word in token_words:\n",
        "      if word not in punctuations:\n",
        "        pos_dict[word]=pos_dict[word]+1\n",
        "  elif corpus[i][\"class\"]=='neg': \n",
        "    for word in token_words:\n",
        "      if word not in punctuations:\n",
        "        neg_dict[word]=neg_dict[word]+1\n",
        "        \n",
        "      \n",
        "pos_dict={k:v for k,v in sorted(pos_dict.items(), key=lambda item:item[1],reverse=True)}\n",
        "neg_dict={k:v for k,v in sorted(neg_dict.items(), key=lambda item:item[1],reverse=True)}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        },
        "id": "BeL_cgSUEXep",
        "outputId": "13fe0b59-594a-46ca-e4cf-aa391a52caae"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig1 = plt.figure()\n",
        "fig2 = plt.figure()\n",
        "ax1 = fig1.add_axes([0,0,1,1])\n",
        "ax2 = fig2.add_axes([0,0,1,1])\n",
        "freqPos = []\n",
        "wordsPos = []\n",
        "freqNeg = []\n",
        "wordsNeg = []\n",
        "\n",
        "limit=23\n",
        "for k in neg_dict:\n",
        "  if limit>0:\n",
        "    wordsNeg.append(k)\n",
        "    freqNeg.append(neg_dict[k])\n",
        "  limit-=1\n",
        "\n",
        "limit=23\n",
        "for k in pos_dict:\n",
        "  if limit>0:\n",
        "    wordsPos.append(k)\n",
        "    freqPos.append(pos_dict[k])\n",
        "  limit-=1\n",
        "\n",
        "ax2.bar(wordsNeg,freqNeg)\n",
        "ax1.bar(wordsPos,freqPos)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kb72e-2bEkyn"
      },
      "source": [
        "words=['the', 'and','i','of','but','is','a','this','to','with','film']\n",
        "stopwords_dict=dict.fromkeys(words,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kz6q0v5-mSwD"
      },
      "source": [
        "# This function can add other features you want that help classification\n",
        "# accuracy, such as bigrams, word prefixes and suffixes, etc.\n",
        "#basic cleaning, lemmatization, stem\n",
        "#it stems, lemmatizes, removes stopwords, sets thresholds of min and max number\n",
        "#of words in Countervectorizer, uses ngrams\n",
        "#each feature changer could be turned on or off\n",
        "def createFancyFeatures(corpus,stopword,stem,lemma,ngram,termFreq,tfidf,mindf,maxdf):\n",
        "  raw=[]\n",
        "  vocab=[]\n",
        "  classes=[]\n",
        "\n",
        "  #in a loop we choose which changes to apply to the features\n",
        "  for i in range(len(corpus)):\n",
        "    sentence=(corpus[i][\"text\"])\n",
        "    if stopword:\n",
        "      sentence=remove_stopwords(sentence,stopwords_dict)\n",
        "    if stem:\n",
        "      sentence=stemSentence(sentence)\n",
        "    if lemma: \n",
        "      sentence=lemmaSentence(sentence)\n",
        "    raw.append(sentence)\n",
        "    classes.append(corpus[i][\"class\"])\n",
        "\n",
        "  #using countvectorizer to count tokens and set thresholds for min and max\n",
        "  vectorizer = CountVectorizer(ngram_range=ngram,min_df=mindf,max_df=maxdf) \n",
        "  #fitting the vectorizer\n",
        "  texts = vectorizer.fit_transform(raw)\n",
        "  vocab_dict = (vectorizer.vocabulary_)\n",
        "\n",
        "\n",
        "  if termFreq:\n",
        "    tf_transformer = TfidfTransformer(use_idf=False).fit(texts) \n",
        "    texts = tf_transformer.transform(texts)\n",
        "\n",
        "  for k in vocab_dict:\n",
        "    vocab.append(k)\n",
        "\n",
        "  # Applying TFIDF \n",
        "  if tfidf:\n",
        "    vectorizer = TfidfVectorizer(ngram_range=ngram,min_df=mindf,max_df=maxdf) \n",
        "    texts = vectorizer.fit_transform(raw)\n",
        "    vocab_dict = (vectorizer.vocabulary_) \n",
        "    for k in vocab_dict:\n",
        "      vocab.append(k)\n",
        "\n",
        "  return texts,classes,vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGfQphUZ92Ya",
        "outputId": "9fbbe7eb-5ffe-4e66-aca1-ffd559e28007"
      },
      "source": [
        "X,y,vocab = createFancyFeatures(corpus=corpus,stopword=False,stem=True,lemma=True,ngram=(1,2),termFreq=False,tfidf=False,mindf=1,maxdf=900000)\n",
        "runEvaluation(X, y, vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------L1 Norm-----------\n",
            "The model's average accuracy is 0.825000\n",
            "The most informative terms for pos are: ['person ca', 'straight he', 'oddest structur', 'current boyfriend', 'cleverli told', 'sandler overprotect', 'solomon if', 'amaz play', 'hi ridicul', 'linda blair', 'about which', 'typ peopl', 'yourself mental', 'underdevelop from', 'goofbal comedi', 'factori at', 'hollywood financi', 'medic doctrin', 'although excel', 'gotten marri']\n",
            "The most informative terms for neg are: ['or futil', 'model two', 'them involv', 'stiff that', 'loanshark', 'lebowski featur', 'use in', 'each main', 'for 400', 'suspici scientist', 'is focus', 'conveni abl', 'theron who', 'pack nice', 'assent short', 'tinier than', 'quickli got', 'finish and', 'to sport', 'curtain']\n",
            "----------L2 Norm-----------\n",
            "The model's average accuracy is 0.854500\n",
            "The most informative terms for pos are: ['underdevelop from', 'amaz play', 'hi ridicul', 'repaint their', 'hollywood financi', 'him read', 'word rating', 'these limit', 'three recent', 'rain or', 'glob in', 'sandler overprotect', 'overload wa', 'rather seem', 'daughter for', 'prospect when', 'clean impress', 'like live', 'person cut', 'school skit']\n",
            "The most informative terms for neg are: ['use in', 'or futil', 'them involv', 'fidel is', '85 percent', 'model two', 'theron who', 'travolta back', 'conveni abl', 'ac dc', 'is focus', 'stockpil quirk', 'lebowski featur', 'lot el', 'mother loss', 'mib agent', 'offer for', 'stiff that', 'hit woman', 'shrek the']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zANSbgKy48F1",
        "outputId": "31f44213-a77e-4203-f182-a19010a6e6a6"
      },
      "source": [
        "X,y,vocab = createFancyFeatures(corpus=corpus,stopword=False,stem=False,lemma=True,ngram=(1,2),termFreq=False,tfidf=False,mindf=1,maxdf=900000)\n",
        "runEvaluation(X, y, vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------L1 Norm-----------\n",
            "The model's average accuracy is 0.824500\n",
            "The most informative terms for pos are: ['gyrating with', 'enough hot', 'meet sugar', 'discovers snuff', 'hope another', 'island 12', 'upside it', 'georgia keaton', 'meet hong', 'sexy film', 'sized bomb', 'had watchabe', 'quiet drama', 'them just', 'car turn', 'something electrical', 'until mike', 'fang encourages', 'of trashing', 'russia to']\n",
            "The most informative terms for neg are: ['past performance', 'to prep', 'time michael', 'that place', 'alert all', 'serbedzija ha', 'unflattering', 'in east', 'lawman reelection', 'definitely failed', 'the talking', 'beatrice but', 'since retained', 'to normal', 'bowden get', 'the trio', 'dump the', 'preceded the', 'boy owen', 'and quote']\n",
            "----------L2 Norm-----------\n",
            "The model's average accuracy is 0.853000\n",
            "The most informative terms for pos are: ['marc hayashi', 'meet hong', 'hope another', 'sexy film', 'nun mark', 'kitty', 'backwards machismo', 'nick rudy', 'the levite', '180 minute', 'vulgar joke', 'tiff and', 'minor setback', 'teaching child', 'half dog', 'allow', 'france to', 'opening crawl', 'fated encounter', 'them just']\n",
            "The most informative terms for neg are: ['the talking', 'to prep', 'past performance', 'journalist leto', 'lovitz burning', 'complicating thing', 'can have', 'dump the', 'serbedzija ha', 'business rival', 'the trio', 'bowden get', 'party pajama', 'uncle who', 'flag while', 'in east', 'waterman of', 'unfounded', 'levitt 3rd', 'alert all']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vz2rCDe1FhK",
        "outputId": "2630fc5c-eb0e-4ff0-9a0f-78fa6f353f5a"
      },
      "source": [
        "words=['the','is','a']\n",
        "stopwords_dict=dict.fromkeys(words,1)\n",
        "X,y,vocab = createFancyFeatures(corpus=corpus,stopword=True,stem=False,lemma=True,ngram=(1,2),termFreq=False,tfidf=False,mindf=5,maxdf=900000)\n",
        "runEvaluation(X, y, vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------L1 Norm-----------\n",
            "The model's average accuracy is 0.819500\n",
            "The most informative terms for pos are: ['through another', 'go under', 'bump into', 'mafioso', 'and stephen', 'room that', 'add more', 'saved', 'spoiled', 'burn', 'shipped', 'end at', 'sour', 'whisper', 'they killed', 'berry', 'if her', 'jimmy stewart', 'liev schreiber', 'aerosmith']\n",
            "The most informative terms for neg are: ['being with', 'in miami', 'come it', 'and energetic', 'have two', 'disliked', 'do have', 'some attempt', 'of there', 'memorable moment', 'over top', 'prison', 'introduced but', 'funny movie', 'unrelated', 'tiny', 're left', 'and father', 'his escape', 'bored by']\n",
            "----------L2 Norm-----------\n",
            "The model's average accuracy is 0.843500\n",
            "The most informative terms for pos are: ['sour', 'dedicates', 'aerosmith', 'choreography', 'jimmy stewart', 'they killed', 'seeing film', 'if her', 'and using', 'go under', 'at least', 'berry', 'of word', 'it okay', 'through another', 'expected', 'but which', 'of cinema', 'to elaborate', 'and part']\n",
            "The most informative terms for neg are: ['prison', 'being with', 'come it', 'horror of', 'happier', 'in miami', 'bored by', 're left', 'tiny', 'fresh air', 'his quest', 'battle are', 'day to', 'introduced but', 'big and', 'have two', 'chockfull', 'role so', 'than many', 'moved by']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9BbbIWOWdjD",
        "outputId": "75c7293b-ac79-47cc-bdf4-27761f40092a"
      },
      "source": [
        "X,y,vocab = createFancyFeatures(corpus=corpus,stopword=False,stem=False,lemma=True,ngram=(1,2),termFreq=False,tfidf=False,mindf=3,maxdf=10000)\n",
        "runEvaluation(X, y, vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------L1 Norm-----------\n",
            "The model's average accuracy is 0.825000\n",
            "The most informative terms for pos are: ['ability in', 'in shakespeare', 'this contrast', 'made an', 'importantly it', 'he grows', 'just window', 'and nice', 'brief but', 'of 100', 'surrender', 'cheesy and', 'rocky start', 'alice is', 'vivid', 'unconvincing in', 'republic', 'memorable and', 'do buy', 'thing found']\n",
            "The most informative terms for neg are: ['first sequence', 'carlin', 'glenda', 'unspeakable', 'sharp and', 'and minute', 'thought would', 'kill him', 'in our', 'however all', 'example of', 'war is', 'something much', 'of 1999', 'and consequently', 'an ending', 'swear', 'material from', 'fine line', 'in session']\n",
            "----------L2 Norm-----------\n",
            "The model's average accuracy is 0.850500\n",
            "The most informative terms for pos are: ['of 100', 'carl sagan', 'importantly it', 'have heart', 'surrender', 'trouble his', 'thing found', 'and brief', 'it power', 'as and', 'move the', 'rasp', 'master plan', 'done very', 'unconvincing in', 'some alien', 'the exaggerated', 'grisham novel', 'similarity', 'film instead']\n",
            "The most informative terms for neg are: ['example of', 'carlin', 'first sequence', 'jawbreaker is', 'sexuality and', 'into series', 'and consequently', 'sharp and', 'an ending', 'sonya', 'standard to', 'swear', 'kill him', 'the coming', 'and minute', 'triumph and', 'glenda', 'however all', 'self deprecation', 'dome']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jq9T2xCuCF1",
        "outputId": "c61a87b0-31ca-46f7-a557-bb2018813dce"
      },
      "source": [
        "X,y,vocab = createFancyFeatures(corpus=corpus,stopword=False,stem=False,lemma=True,ngram=(1,2),termFreq=False,tfidf=False,mindf=3,maxdf=30000)\n",
        "runEvaluation(X, y, vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------L1 Norm-----------\n",
            "The model's average accuracy is 0.825000\n",
            "The most informative terms for pos are: ['ability in', 'in shakespeare', 'this contrast', 'made an', 'importantly it', 'he grows', 'just window', 'and nice', 'brief but', 'of 100', 'surrender', 'cheesy and', 'rocky start', 'alice is', 'vivid', 'unconvincing in', 'republic', 'memorable and', 'do buy', 'thing found']\n",
            "The most informative terms for neg are: ['first sequence', 'carlin', 'glenda', 'unspeakable', 'sharp and', 'and minute', 'thought would', 'kill him', 'in our', 'however all', 'example of', 'war is', 'something much', 'of 1999', 'and consequently', 'an ending', 'swear', 'material from', 'fine line', 'in session']\n",
            "----------L2 Norm-----------\n",
            "The model's average accuracy is 0.850500\n",
            "The most informative terms for pos are: ['of 100', 'carl sagan', 'importantly it', 'have heart', 'surrender', 'trouble his', 'thing found', 'and brief', 'it power', 'as and', 'move the', 'rasp', 'master plan', 'done very', 'unconvincing in', 'some alien', 'the exaggerated', 'grisham novel', 'similarity', 'film instead']\n",
            "The most informative terms for neg are: ['example of', 'carlin', 'first sequence', 'jawbreaker is', 'sexuality and', 'into series', 'and consequently', 'sharp and', 'an ending', 'sonya', 'standard to', 'swear', 'kill him', 'the coming', 'and minute', 'triumph and', 'glenda', 'however all', 'self deprecation', 'dome']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvZWouxW64qH",
        "outputId": "e736a936-9a94-4c95-f3ec-f736d1dbb9c4"
      },
      "source": [
        "X,y,vocab = createFancyFeatures(corpus=corpus,stopword=False,stem=False,lemma=True,ngram=(1,2),termFreq=False,tfidf=False,mindf=3,maxdf=7000)\n",
        "runEvaluation(X, y, vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------L1 Norm-----------\n",
            "The model's average accuracy is 0.825500\n",
            "The most informative terms for pos are: ['ability in', 'in shakespeare', 'this contrast', 'made an', 'importantly it', 'he grows', 'just window', 'and nice', 'brief but', 'of 100', 'surrender', 'cheesy and', 'rocky start', 'alice is', 'vivid', 'unconvincing in', 'republic', 'memorable and', 'do buy', 'thing found']\n",
            "The most informative terms for neg are: ['first sequence', 'carlin', 'glenda', 'unspeakable', 'sharp and', 'and minute', 'thought would', 'kill him', 'in our', 'however all', 'example of', 'war is', 'something much', 'of 1999', 'and consequently', 'an ending', 'swear', 'material from', 'fine line', 'in session']\n",
            "----------L2 Norm-----------\n",
            "The model's average accuracy is 0.850500\n",
            "The most informative terms for pos are: ['of 100', 'carl sagan', 'importantly it', 'have heart', 'surrender', 'trouble his', 'thing found', 'and brief', 'it power', 'as and', 'move the', 'rasp', 'master plan', 'done very', 'unconvincing in', 'some alien', 'the exaggerated', 'grisham novel', 'similarity', 'film instead']\n",
            "The most informative terms for neg are: ['example of', 'carlin', 'first sequence', 'jawbreaker is', 'sexuality and', 'into series', 'and consequently', 'sharp and', 'an ending', 'sonya', 'standard to', 'swear', 'kill him', 'the coming', 'and minute', 'triumph and', 'glenda', 'however all', 'self deprecation', 'dome']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ph2uH3txoTw-",
        "outputId": "f2c40a11-2d80-41ef-fb1e-7c01d59c7e83"
      },
      "source": [
        "X,y,vocab = createFancyFeatures(corpus=corpus,stopword=False,stem=False,lemma=True,ngram=(1,2),termFreq=False,tfidf=False,mindf=3,maxdf=5000)\n",
        "runEvaluation(X, y, vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------L1 Norm-----------\n",
            "The model's average accuracy is 0.824500\n",
            "The most informative terms for pos are: ['ability in', 'in shakespeare', 'this contrast', 'made an', 'importantly it', 'he grows', 'just window', 'and nice', 'brief but', 'of 100', 'surrender', 'cheesy and', 'rocky start', 'alice is', 'vivid', 'unconvincing in', 'republic', 'memorable and', 'do buy', 'thing found']\n",
            "The most informative terms for neg are: ['first sequence', 'carlin', 'glenda', 'unspeakable', 'sharp and', 'and minute', 'thought would', 'kill him', 'in our', 'however all', 'example of', 'war is', 'something much', 'of 1999', 'and consequently', 'an ending', 'swear', 'material from', 'fine line', 'in session']\n",
            "----------L2 Norm-----------\n",
            "The model's average accuracy is 0.850500\n",
            "The most informative terms for pos are: ['of 100', 'carl sagan', 'importantly it', 'have heart', 'surrender', 'trouble his', 'thing found', 'and brief', 'it power', 'as and', 'move the', 'rasp', 'master plan', 'done very', 'unconvincing in', 'some alien', 'the exaggerated', 'grisham novel', 'similarity', 'film instead']\n",
            "The most informative terms for neg are: ['example of', 'carlin', 'first sequence', 'jawbreaker is', 'sexuality and', 'into series', 'and consequently', 'sharp and', 'an ending', 'sonya', 'standard to', 'swear', 'kill him', 'the coming', 'and minute', 'triumph and', 'glenda', 'however all', 'self deprecation', 'dome']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLUXrHPrnVju",
        "outputId": "75b4dc27-65a2-43c9-cc23-ef9eca433b87"
      },
      "source": [
        "X,y,vocab = createFancyFeatures(corpus=corpus,stopword=False,stem=True,lemma=True,ngram=(1,2),termFreq=False,tfidf=False,mindf=3,maxdf=5000)\n",
        "runEvaluation(X, y, vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------L1 Norm-----------\n",
            "The model's average accuracy is 0.821000\n",
            "The most informative terms for pos are: ['place even', 'also star', 'afterward', 'detail how', 'brain and', 'show ha', 'worthi', 'spectacular and', 'everyth is', 'zak', 'she commit', 'we wo', 'thi great', 'fear is', 'nois and', 'the park', 'subtleti of', 'man for', 'kattan', 'good but']\n",
            "The most informative terms for neg are: ['arguabl more', 'awesom although', 'up first', '1960 and', 'kelli and', 'alien invas', 'atmospher but', 'fill up', 'transsexu', 'visual', 'like armageddon', 'parent that', 'some promis', 'run out', 'actual happen', 'lead are', 'there giant', 'the singer', 'who special', 'reason in']\n",
            "----------L2 Norm-----------\n",
            "The model's average accuracy is 0.854500\n",
            "The most informative terms for pos are: ['we wo', 'worthi', 'spectacular and', 'pour from', 'song for', 'core is', 'differ kind', 'subtleti of', 'two young', 'the hous', 'everyth is', 'life now', 'film made', 'ward and', 'is talent', 'aloof', 'is repres', 'detail how', 'and creat', 'show ha']\n",
            "The most informative terms for neg are: ['visual', 'awesom although', 'up first', 'arguabl more', 'hand on', 'run out', 'novel and', 'been fascin', 'some promis', 'duma', 'like armageddon', 'transsexu', 'arliss', '1960 and', 'of refer', 'cromwel and', 'most harrow', 'lead are', 'fill up', 'who special']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dp65vNIuCbsw",
        "outputId": "a6bcb08e-8452-4e81-bf04-8e43c96ac91b"
      },
      "source": [
        "X,y,vocab = createFancyFeatures(corpus=corpus,stopword=True,stem=True,lemma=True,ngram=(1,2),termFreq=False,tfidf=False,mindf=3,maxdf=5000)\n",
        "runEvaluation(X, y, vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------L1 Norm-----------\n",
            "The model's average accuracy is 0.814500\n",
            "The most informative terms for pos are: ['cours one', 'scene first', 'addi', 'releas featur', 'need look', 'get sleep', 'almost like', 'butt', 'martha plimpton', 'fleet', 'mani subplot', 'investig murder', 'welcom sarajevo', 'peopl town', 'even worth', 'lombardo matt', 'got noth', 'usual onli', 'machin human', 'home shop']\n",
            "The most informative terms for neg are: ['amount humor', 'not world', 'scorses finest', 'nod', 'joseph conrad', 'sum total', 'film re', 'interest play', 'great love', 'could look', 'turn peopl', 'consumpt', 'imagin movi', 'odett', 'chill', 'time tell', 'big hous', 'pa', 'everi step', 'actual make']\n",
            "----------L2 Norm-----------\n",
            "The model's average accuracy is 0.852500\n",
            "The most informative terms for pos are: ['butt', 'usual onli', 'wander aimlessli', 'scene first', 'bubblegum', 'get sleep', 'hit mark', 'mani plot', 'red octob', 'wed', 'overarch', 'home shop', 'port', 'sheryl lee', 'life son', 'peopl town', 'investig murder', 'direct first', 'drill sergeant', 'harlem night']\n",
            "The most informative terms for neg are: ['emperor', 'amount humor', 'scorses finest', 'could look', 'never feel', 'chill', 'consumpt', 'play bit', 'joseph conrad', 'violenc howev', 'quit well', 'great love', 'outta', 'nod', 'odett', 'mayb littl', 'sum total', 'not world', 'film re', 'macdonald']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spbN7VBICwPe",
        "outputId": "95d984cf-0167-434d-a52b-4aa50f8545b4"
      },
      "source": [
        "X,y,vocab = createFancyFeatures(corpus=corpus,stopword=True,stem=True,lemma=True,ngram=(1,3),termFreq=False,tfidf=False,mindf=3,maxdf=5000)\n",
        "runEvaluation(X, y, vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------L1 Norm-----------\n",
            "The model's average accuracy is 0.814500\n",
            "The most informative terms for pos are: ['thing ye', 'lloyd', 'walt disney', 'perform career', 'music veri', 'nap', 'onset', 'life becom', 'angela', 'buscemi jon', 'oeuvr', 'understand much', 'gibson nt', 'lisa mari', 'nt qualifi', 'almost everi', 'hope catch', 'ashton', 'expect like someth', 'thing interest']\n",
            "The most informative terms for neg are: ['part ii', 'cement place', 'charact world', 'carri', 'action get', 'attent away', 'blare', 'bad movi nt', 'also mean', 'solid film', 'time second', 'dozen peopl', 'speak directli', 'spent watch', 'speed', 'intellig one', 'past five', 'big budget', 'statement not', 'bootleg']\n",
            "----------L2 Norm-----------\n",
            "The model's average accuracy is 0.852500\n",
            "The most informative terms for pos are: ['life becom', 'ashton', 'virtuoso', 'lloyd', 'instead concentr', 'nap', 'bill clinton', 'upbring', 'heather matarazzo', 'andor', 'bond girl', 'thing interest', 'like seen', 'convuls', 'act director', 'lisa mari', 'gibson nt', 'rare see', 'weak dialogu', 'kind woman']\n",
            "The most informative terms for neg are: ['goro', 'part ii', 'charact world', 'solid film', 'also pretti good', 'speak directli', 'speed', 'film problem', 'action get', 'minor chang', 'hope promis', 'also mean', 'malroux', 'carri', 'spent watch', 'caligula', 'attent away', 'cement place', 'bad movi nt', 'blare']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHJi5q_xIoUO",
        "outputId": "c5a7b670-8031-4f3b-fd53-fd1058219d3d"
      },
      "source": [
        "X,y,vocab = createFancyFeatures(corpus=corpus,stopword=False,stem=True,lemma=True,ngram=(1,3),termFreq=True,tfidf=False,mindf=3,maxdf=5000)\n",
        "runEvaluation(X, y, vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------L1 Norm-----------\n",
            "The model's average accuracy is 0.739000\n",
            "The most informative terms for pos are: ['the film final', 'aureliu', 'to touch the', 'me to believ', 'pay money', 'the audienc while', 'and director', 'him home', 'hi all', 'seri which', 'to turn thi', 'is no sen', 'creat for the', 'it lack in', 'is unconvinc', 'wa inde', 'to make long', 'establish shot', 'manhattan', 'and more than']\n",
            "The most informative terms for neg are: ['in the style', 'often hard to', 'other have', 'the gratuit', 'up the charact', 'poke', 'uninform', 'mani time have', 'in enemi', 'accuraci', 'shakespear is', 'whoever', 'convent of the', 'hiss', 'in dream', 'of ten', 'ascend to', 'regard to the', 'an excus', 'for variou']\n",
            "----------L2 Norm-----------\n",
            "The model's average accuracy is 0.776000\n",
            "The most informative terms for pos are: ['the audienc while', 'seri which', 'aureliu', 'pay money', 'the film final', 'him home', 'is no sen', 'and director', 'me to believ', 'to touch the', 'to turn thi', 'is unconvinc', 'to make long', 'and more than', 'establish shot', 'it lack in', 'can hear the', 'creat for the', 'hi all', 'again in']\n",
            "The most informative terms for neg are: ['in the style', 'the gratuit', 'often hard to', 'other have', 'mani time have', 'ascend to', 'accuraci', 'uninform', 'first there is', 'convent of the', 'in enemi', 'shakespear is', 'hiss', 'an excus', 'thi miser', 'for variou', 'whoever', 'poke', 'regard to the', 'up the charact']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lgmuzcPIra7",
        "outputId": "440dd96f-9cd0-4ce0-ad45-15d503931d8f"
      },
      "source": [
        "X,y,vocab = createFancyFeatures(corpus=corpus,stopword=False,stem=True,lemma=True,ngram=(1,3),termFreq=False,tfidf=True,mindf=3,maxdf=5000)\n",
        "runEvaluation(X, y, vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------L1 Norm-----------\n",
            "The model's average accuracy is 0.730000\n",
            "The most informative terms for pos are: ['the audienc while', 'the film final', 'seri which', 'pay money', 'creat for the', 'aureliu', 'is no sen', 'hi hand at', 'it lack in', 'narrat from', 'foursom', 'bar', 'have done better', 'and director', 'you got ta', 'sequel unfortun', 'well sorri', 'funni unfortun the', 'be parodi', 'other action']\n",
            "The most informative terms for neg are: ['in the style', 'up the charact', 'regard to the', 'poke', 'the gratuit', 'other have', 'often hard to', 'the entir experi', 'whoever', 'uninform', 'tortur by', 'mani time have', 'first there is', 'in dream', 'ascend to', 'been known', 'be parodi', 'well sorri', 'last danc', 'sequel unfortun']\n",
            "----------L2 Norm-----------\n",
            "The model's average accuracy is 0.825500\n",
            "The most informative terms for pos are: ['the audienc while', 'seri which', 'it lack in', 'is no sen', 'pay money', 'the film final', 'have done better', 'aureliu', 'creat for the', 'and more than', 'narrat from', 'can hear the', 'and director', 'hi hand at', 'is unconvinc', 'him home', 'the background', 'foursom', 'slay', 'that deal']\n",
            "The most informative terms for neg are: ['in the style', 'the gratuit', 'other have', 'regard to the', 'up the charact', 'poke', 'first there is', 'the entir experi', 'uninform', 'ascend to', 'mani time have', 'often hard to', 'tortur by', 'whoever', 'in dream', 'the truest', 'narrat is', 'have run', 'in enemi', 'go at']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UdjyPelJUrt",
        "outputId": "1634e491-4ff3-4a3a-e00e-dd19718017a3"
      },
      "source": [
        "X,y,vocab = createFancyFeatures(corpus=corpus,stopword=True,stem=True,lemma=True,ngram=(1,3),termFreq=False,tfidf=True,mindf=3,maxdf=5000)\n",
        "runEvaluation(X, y, vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------L1 Norm-----------\n",
            "The model's average accuracy is 0.741500\n",
            "The most informative terms for pos are: ['of contriv', 'after see it', 'score by john', 'on stephen king', 'of youngster', 'thing down', 'from high school', 'and on', 'would be littl', 'it case', 'garri', 'poseidon adventur', 'open on', 'okay so', 'it own good', 'it think', 'done but', 'rambuncti', 'that work in', 'kind of role']\n",
            "The most informative terms for neg are: ['blame here', 'hobb', 'brother from', 'job of portray', 'for not', 'rel newcom', 'wa shoot for', 'kkk', 'not deserv', 'mass', 'heard when', 'wa talk', 'nt look that', 'ha jacki', 'of fairli', 'watch such', 'unknown', 'cinema 18 guilderland', 'veri success', 'of kid']\n",
            "----------L2 Norm-----------\n",
            "The model's average accuracy is 0.826000\n",
            "The most informative terms for pos are: ['of contriv', 'would be littl', 'thing down', 'on stephen king', 'after see it', 'score by john', 'it own good', 'it case', 'of youngster', 'and on', 'poseidon adventur', 'from high school', 'garri', 'he plan to', 'open on', 'have done with', 'it think', 'to appear on', 'local journalist', 'men on']\n",
            "The most informative terms for neg are: ['blame here', 'rel newcom', 'brother from', 'for not', 'hobb', 'job of portray', 'kkk', 'wa shoot for', 'nt look that', 'not deserv', 'heard when', 'mass', 'ha jacki', 'wa talk', 'veri success', 'one case', 'studio are', 'to hell to', 'in 1983', 'punch and']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfTBqBltXe7Y"
      },
      "source": [
        "# given a numpy matrix representation of the features for the training set, the \n",
        "# vector of true classes for each example, and the vocabulary as described \n",
        "# above, this computes the accuracy of the model using leave one out cross \n",
        "# validation and reports the most indicative features for each class\n",
        "\n",
        "def evaluateModel(X,y,vocab,penalty=\"l1\"):\n",
        "  # create and fit the model\n",
        "  model = LogisticRegression(penalty=penalty,solver=\"liblinear\")\n",
        "  results = cross_validate(model,X,y,cv=KFold(n_splits=10, shuffle=True, random_state=1))\n",
        "  \n",
        "  # determine the average accuracy\n",
        "  scores = results[\"test_score\"]\n",
        "  avg_score = sum(scores)/len(scores)\n",
        "  \n",
        "  # determine the most informative features\n",
        "  # this requires us to fit the model to everything, because we need a\n",
        "  # single model to draw coefficients from, rather than 26\n",
        "  model.fit(X,y)\n",
        "  class0_weight_sorted = model.coef_[0, :].argsort()\n",
        "  class1_weight_sorted = (-model.coef_[0, :]).argsort()\n",
        "\n",
        "  termsToTake = 20\n",
        "  class0_indicators = [vocab[i] for i in class0_weight_sorted[:termsToTake]]\n",
        "  class1_indicators = [vocab[i] for i in class1_weight_sorted[:termsToTake]]\n",
        "\n",
        "  if model.classes_[0] == \"pos\":\n",
        "    return avg_score,class0_indicators,class1_indicators\n",
        "  else:\n",
        "    return avg_score,class1_indicators,class0_indicators\n",
        "\n",
        "def runEvaluation(X,y,vocab):\n",
        "  print(\"----------L1 Norm-----------\")\n",
        "  avg_score,pos_indicators,neg_indicators = evaluateModel(X,y,vocab,\"l1\")\n",
        "  print(\"The model's average accuracy is %f\"%avg_score)\n",
        "  print(\"The most informative terms for pos are: %s\"%pos_indicators)\n",
        "  print(\"The most informative terms for neg are: %s\"%neg_indicators)\n",
        "  #this call will fit a model with L2 normalization\n",
        "  print(\"----------L2 Norm-----------\")\n",
        "  avg_score,pos_indicators,neg_indicators = evaluateModel(X,y,vocab,\"l2\")\n",
        "  print(\"The model's average accuracy is %f\"%avg_score)\n",
        "  print(\"The most informative terms for pos are: %s\"%pos_indicators)\n",
        "  print(\"The most informative terms for neg are: %s\"%neg_indicators)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72OUet02TjBo"
      },
      "source": [
        "Run the following to train and evaluate two models using basic features:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sjxLL2PTrJi"
      },
      "source": [
        "Run the following to train and evaluate two models using extended features:"
      ]
    }
  ]
}